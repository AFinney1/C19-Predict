{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import streamlit as st\n",
    "import streamlit.components.v1 as components\n",
    "import os\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas.io.stata import StataReader\n",
    "from Case_pipeline import get_cases\n",
    "from PIL import Image\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(case_df):\n",
    "    print(\"Preprocessing...\")\n",
    "    columns = case_df.columns\n",
    "    #datecolumns = case_df.columns()\n",
    "    case_df.drop(columns[:5], inplace=True, axis=1)\n",
    "    region_col = list(case_df.columns.values)\n",
    "    region_col_ax = region_col[11:]\n",
    "    plot_cols = region_col_ax\n",
    "    st.text(\"Case data last updated: \" + str(case_df.columns[-1]))\n",
    "    try:\n",
    "        state_name = st.text_input(\"Enter state name \",) #'Mississippi') #or 'Mississippi'\n",
    "    except:\n",
    "        st.error(\"Please enter the proper name of the state without whitespace(e.g. 'Texas', not 'texas ')\")\n",
    "    region = case_df.loc[case_df['Province_State'] == state_name]\n",
    "    #print(region)\n",
    "    #st.write(region)\n",
    "    county_list = region['Admin2']\n",
    "    #default_county = county_list.iloc[0]\n",
    "    try:\n",
    "        county_name = st.text_input(\"Enter county name \", )#\"Hinds\")# or default_county\n",
    "    except:\n",
    "        st.error(\"Please enter the proper name of the county without whitespace(e.g. 'Austin', not 'austin '\")   \n",
    "    county = region.loc[region['Admin2'] == county_name]\n",
    "    columns = columns[5:11]\n",
    "    county.drop(columns, inplace=True, axis=1)\n",
    "    date_index = range(len(county))\n",
    "    county = county.transpose()\n",
    "    lastdate = (str(region.columns[-1]))\n",
    "    col_length = len(region.columns)\n",
    "    initial_startdate = (str(region.columns[6]))\n",
    "    test_startdate = (str(region.columns[int(col_length*.803)]))\n",
    "    val_startdate = (str(region.columns[int(col_length*.4)]))\n",
    "    print(test_startdate)\n",
    "    return region_col, region_col_ax, region, county, initial_startdate, val_startdate, test_startdate, county_name, state_name, lastdate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_test_val_split(preprocessed_data):\n",
    "    county = preprocessed_data[3]\n",
    "    county_length = len(county)\n",
    "    training_df = county[0:int(county_length*0.4)] # training set for model parameter optimization\n",
    "    try:\n",
    "        val_df = county[int(county_length*0.4):int(county_length*0.8)] #validation set used to find optimal model hyperparameters\n",
    "    except:\n",
    "        val_df = county[int(county_length*0.4):int(county_length*0.798)] #second splice needed in case previous split doesn't work based on odd vs even days.\n",
    "    test_df = county[int(county_length*0.8):] #test set used to determine model performance in general\n",
    "    num_feature_days = county.shape[0]\n",
    "    print(\"Number of Days:\", str(num_feature_days))\n",
    "    training_mean = training_df.mean()\n",
    "    training_std = training_df.std()\n",
    "    print(\"TYPES: \\n\", type(training_std))\n",
    "    return(training_df, val_df, test_df, training_mean, training_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize(df, training_mean, training_std):\n",
    "    normed_df = (df - training_mean)/training_std\n",
    "    return normed_df\n",
    "\n",
    "\n",
    "def denormalize(df, training_mean, training_std ):\n",
    "    #denormalized_df = training_std.values/(df.values - training_mean.values)\n",
    "    denormalized_df = training_std.values*df.values + training_mean.values\n",
    "    return denormalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_data_loader(x_train, x_val, x_test):\n",
    "\n",
    "    train_features = torch.Tensor(x_train.values)\n",
    "    val_features = torch.Tensor(x_val.values)\n",
    "    test_features = torch.Tensor(x_test.values)\n",
    "    print(train_features.shape)\n",
    "    train_targets = torch.Tensor(x_train.values)\n",
    "    val_targets = torch.Tensor(x_val.values)\n",
    "    test_targets = torch.Tensor(x_test.values)\n",
    "    batch_size = 1\n",
    "\n",
    "    train_dataset = TensorDataset(train_features, train_targets)\n",
    "    val_dataset = TensorDataset(val_features, val_targets)\n",
    "    test_dataset = TensorDataset(test_features, test_targets)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    print(train_loader)\n",
    "    print(train_dataset)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader_one = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "    return train_loader, val_loader, test_loader, test_loader_one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        # Defining the number of layers and the nodes in each layer\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
    "        )\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initializing hidden state for first input with zeros\n",
    "\n",
    "        #x = torch.FloatTensor(x)\n",
    "        h0 = torch.zeros(self.layer_dim, len(x), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Initializing cell state for first input with zeros\n",
    "        c0 = torch.zeros(self.layer_dim, len(x), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        # Forward propagation by passing in the input, hidden state, and cell state into the model\n",
    "  \n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
    "        # so that it can fit into the fully connected layer\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
