{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import os\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas.io.stata import StataReader\n",
    "from PIL import Image\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cases():\n",
    "    '''\n",
    "    window = tkinter.Tk()\n",
    "    window.title(\"Case data explorer\")\n",
    "    window.withdraw()\n",
    "    '''\n",
    "    cwd = os.getcwd()\n",
    "    csv_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv\"\n",
    "    req = requests.get(csv_url, allow_redirects=True)\n",
    "    open('Local_case_data/time_series_covid19_confirmed_US.csv', 'wb').write(req.content)\n",
    "    #f = filedialog.askopenfilename(initialdir=\"/Local_case_data/\",initialfile=\"time_series_covid19_confirmed_US.csv\", title=\"Select a File\",filetypes=((\"CSV files\", \"*.csv*\"),(\"all files\", \"*.*\")), )\n",
    "    cwd = os.getcwd()\n",
    "    f = cwd+\"/Local_case_data/time_series_covid19_confirmed_US.csv\"\n",
    "    #label_file_explorer.configure(text=\"File Opened: \"+f)\n",
    "    #f.close()\n",
    "    case_df = pd.read_csv(str(f))\n",
    "    #window.mainloop\n",
    "    #window.destroy()\n",
    "    return case_df\n",
    "cases = get_cases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(case_df):\n",
    "    print(\"Preprocessing...\")\n",
    "    columns = case_df.columns\n",
    "    #datecolumns = case_df.columns()\n",
    "    case_df.drop(columns[:5], inplace=True, axis=1)\n",
    "    region_col = list(case_df.columns.values)\n",
    "    region_col_ax = region_col[11:]\n",
    "    plot_cols = region_col_ax\n",
    "    print(\"Case data last updated: \" + str(case_df.columns[-1]))\n",
    "    state_name ='Mississippi' #or 'Mississippi'\n",
    "    region = case_df.loc[case_df['Province_State'] == state_name]\n",
    "    #print(region)\n",
    "    #st.write(region)\n",
    "    county_list = region['Admin2']\n",
    "    #default_county = county_list.iloc[0]\n",
    "    county_name =  'Hinds'#\"Hinds\")# or default_county\n",
    "    county = region.loc[region['Admin2'] == county_name]\n",
    "    columns = columns[5:11]\n",
    "    county.drop(columns, inplace=True, axis=1)\n",
    "    date_index = range(len(county))\n",
    "    county = county.transpose()\n",
    "    lastdate = (str(region.columns[-1]))\n",
    "    col_length = len(region.columns)\n",
    "    initial_startdate = (str(region.columns[6]))\n",
    "    test_startdate = (str(region.columns[int(col_length*.803)]))\n",
    "    val_startdate = (str(region.columns[int(col_length*.4)]))\n",
    "    print(test_startdate)\n",
    "    return region_col, region_col_ax, region, county, initial_startdate, val_startdate, test_startdate, county_name, state_name, lastdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_test_val_split(preprocessed_data):\n",
    "    county = preprocessed_data[3]\n",
    "    county_length = len(county)\n",
    "    training_df = county[0:int(county_length*0.4)] # training set for model parameter optimization\n",
    "    try:\n",
    "        val_df = county[int(county_length*0.4):int(county_length*0.8)] #validation set used to find optimal model hyperparameters\n",
    "    except:\n",
    "        val_df = county[int(county_length*0.4):int(county_length*0.798)] #second splice needed in case previous split doesn't work based on odd vs even days.\n",
    "    test_df = county[int(county_length*0.8):] #test set used to determine model performance in general\n",
    "    num_feature_days = county.shape[0]\n",
    "    print(\"Number of Days:\", str(num_feature_days))\n",
    "    training_mean = training_df.mean()\n",
    "    training_std = training_df.std()\n",
    "    print(\"TYPES: \\n\", type(training_std))\n",
    "    return training_df, val_df, test_df, training_mean, training_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n",
      "Case data last updated: 8/12/22\n",
      "2/8/22\n",
      "Number of Days: 934\n",
      "TYPES: \n",
      " <class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/austin/anaconda3/envs/dashx/lib/python3.8/site-packages/pandas/core/frame.py:4305: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "seq_len = 35\n",
    "batch_size = 55\n",
    "x_train, x_val, x_test, training_mean, training_std = train_test_val_split(preprocessing(cases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize(df, training_mean, training_std):\n",
    "    normed_df = (df - training_mean)/training_std\n",
    "    return normed_df\n",
    "\n",
    "\n",
    "def denormalize(df, training_mean, training_std ):\n",
    "    #denormalized_df = training_std.values/(df.values - training_mean.values)\n",
    "    denormalized_df = training_std.values*df.values + training_mean.values\n",
    "    return denormalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_data_loader(x_train, x_val, x_test):\n",
    "\n",
    "    train_features = torch.Tensor(x_train.values)\n",
    "    val_features = torch.Tensor(x_val.values)\n",
    "    test_features = torch.Tensor(x_test.values)\n",
    "    print(train_features.shape)\n",
    "    train_targets = torch.Tensor(x_train.values)\n",
    "    val_targets = torch.Tensor(x_val.values)\n",
    "    test_targets = torch.Tensor(x_test.values)\n",
    "    batch_size = 1\n",
    "\n",
    "    train_dataset = TensorDataset(train_features, train_targets)\n",
    "    val_dataset = TensorDataset(val_features, val_targets)\n",
    "    test_dataset = TensorDataset(test_features, test_targets)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    print(train_loader)\n",
    "    print(train_dataset)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader_one = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "    return train_loader, val_loader, test_loader, test_loader_one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 5 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/austin/Documents/Repositories/C19-Predict/Case_Notebook.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/austin/Documents/Repositories/C19-Predict/Case_Notebook.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m hidden_size \u001b[39m=\u001b[39m seq_len\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/austin/Documents/Repositories/C19-Predict/Case_Notebook.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m num_layers \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/austin/Documents/Repositories/C19-Predict/Case_Notebook.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m covid_forecast_model \u001b[39m=\u001b[39m LSTM_Model(input_dim, hidden_size, num_layers, batch_size, \u001b[39m0.2\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/austin/Documents/Repositories/C19-Predict/Case_Notebook.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m loss_function \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mMSELoss() \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/austin/Documents/Repositories/C19-Predict/Case_Notebook.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m optimizer  \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(covid_forecast_model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.017\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 5 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "class LSTM_Model(torch.nn.Module):\n",
    "    def __init__(self, input_dim , hidden_size , num_layers, batch_size):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm = torch.nn.LSTM(input_size=input_dim , hidden_size = hidden_size , num_layers= num_layers )\n",
    "        self.fc = torch.nn.Linear(hidden_size,1)\n",
    "\n",
    "    def forward(self,x,hn,cn):\n",
    "        out , (hn,cn) = self.lstm(x , (hn,cn))\n",
    "        final_out = self.fc(out[-1])\n",
    "        return final_out,hn,cn\n",
    "\n",
    "    def predict(self,x):\n",
    "        hn,cn  = self.init()\n",
    "        final_out = self.fc(hn[-1])\n",
    "        return final_out\n",
    "\n",
    "    def init(self):\n",
    "        h0 =  torch.zeros(self.num_layers , self.batch_size , self.hidden_size)\n",
    "        c0 =  torch.zeros(self.num_layers , self.batch_size , self.hidden_size)\n",
    "        return h0 , c0\n",
    "\n",
    "input_dim = 1\n",
    "hidden_size = seq_len\n",
    "num_layers = 5\n",
    "covid_forecast_model = LSTM_Model(input_dim, hidden_size, num_layers, batch_size)\n",
    "\n",
    "loss_function = torch.nn.MSELoss() \n",
    "optimizer  = torch.optim.Adam(covid_forecast_model.parameters(), lr=0.017) # used adaptive moment estimation to optimize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def train(dataloader, model):\n",
    "    predictions = []\n",
    "    loss_list = []\n",
    "    hn , cn = model.init()\n",
    "    model.train()\n",
    "    for batch , item in enumerate(dataloader):\n",
    "        x , y = item\n",
    "        y = y.type(torch.FloatTensor)\n",
    "        #x = x.to(device)\n",
    "        #y = y.to(device)\n",
    "        out , hn , cn = model(x.reshape(seq_len,batch_size,-1),hn,cn)\n",
    "        out = out.view(-1)\n",
    "        # print(out.shape)\n",
    "        # print(y.shape)\n",
    "        loss = loss_function(out.reshape(batch_size) , y)\n",
    "        hn = hn.detach()\n",
    "        cn = cn.detach()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Training Loss: {loss.item()}')\n",
    "        if batch == len(dataloader)-1:\n",
    "            loss = loss.item()\n",
    "            print(f\"Train loss: {loss:>7f} \")\n",
    "        loss_list.append(loss)\n",
    "        predictions.append(out.detach().numpy())\n",
    "        return predictions, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    predictions = []\n",
    "    loss_list = []\n",
    "    hn , cn = model.init()\n",
    "    model.eval()\n",
    "    for batch , item in enumerate(dataloader):\n",
    "        x , y = item\n",
    "        y = y.type(torch.FloatTensor)\n",
    "        #x = x.to(device)\n",
    "        #y = y.to(device)\n",
    "        out , hn , cn = model(x.reshape(seq_len,batch_size,1),hn,cn)\n",
    "        loss = loss_function(out.reshape(batch_size) , y)\n",
    "        print(f\"test loss: {loss.item():>7f} \")\n",
    "        if batch == len(dataloader)-1:\n",
    "            loss = loss.item()\n",
    "            print(f\"Test loss: {loss:>7f} \")\n",
    "        predictions.append(out.detach().numpy())\n",
    "        loss_list.append(loss)\n",
    "        return predictions, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([373, 1])\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fca1c33c340>\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x7fc9dd5dcf70>\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, test_loader_one = torch_data_loader(x_train, x_val, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: \n"
     ]
    },
    {
     "ename": "ModuleAttributeError",
     "evalue": "'LSTMModel' object has no attribute 'init'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/austin/Documents/Repositories/C19-Predict/Case_Notebook.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/austin/Documents/Repositories/C19-Predict/Case_Notebook.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/austin/Documents/Repositories/C19-Predict/Case_Notebook.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/austin/Documents/Repositories/C19-Predict/Case_Notebook.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     train(train_loader, covid_forecast_model)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/austin/Documents/Repositories/C19-Predict/Case_Notebook.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m test_predictions \u001b[39m=\u001b[39m test(test_loader, covid_forecast_model)\n",
      "\u001b[1;32m/home/austin/Documents/Repositories/C19-Predict/Case_Notebook.ipynb Cell 12\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/austin/Documents/Repositories/C19-Predict/Case_Notebook.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m predictions \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/austin/Documents/Repositories/C19-Predict/Case_Notebook.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m loss_list \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/austin/Documents/Repositories/C19-Predict/Case_Notebook.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m hn , cn \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49minit()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/austin/Documents/Repositories/C19-Predict/Case_Notebook.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/austin/Documents/Repositories/C19-Predict/Case_Notebook.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch , item \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n",
      "File \u001b[0;32m~/anaconda3/envs/dashx/lib/python3.8/site-packages/torch/nn/modules/module.py:778\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m    777\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m--> 778\u001b[0m \u001b[39mraise\u001b[39;00m ModuleAttributeError(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    779\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'LSTMModel' object has no attribute 'init'"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}: \")\n",
    "    train(train_loader, covid_forecast_model)\n",
    "test_predictions = test(test_loader, covid_forecast_model)\n",
    "#print(test_predictions[:][:][:][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('dashx')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de5c184b332d5e58c9dc43895afb5dcc9751d53cc98ed2b6edac72b496a59376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
